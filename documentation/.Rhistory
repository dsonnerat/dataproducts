rpois(10)
rpois(10,0)
rpois(10,1:2)
rpois(100,1:2)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
rep(0:1, each = 5)
rnorm(10, 0, 20)
summary(rnomr(10,0,20))
summarize(rnomr(10,0,20))
summarise(rnomr(10,0,20))
sumarise(rnomr(10,0,20))
sumary(rnomr(10,0,20))
summary(rnomr(10,0,20))
summary(rnorm(10,0,20))
set.seed(10)
x <- rep(0:1, each = 5)
y <- 0.5 + 2 * x + e
plot(y)
y
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(y)
?rbinom
?Rprof
date()
?sample
1E5
letters
?download.file
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile='data.csv', method='curl')
data <- read.csv('data.csv')
head(data)
data[,VAL] <- as.numeric(data[,VAL])
data$VAL <- as.numeric(data$VAL)
head(data$VAL)
?subset
a  <- subet(data,!is.na(data$VAL))
a  <- subset(data,!is.na(data$VAL))
head(data$VAL)
head(a$VAL)
a$VAL>1000000
a$VAL>=1000000
a$VAL[,a$VAL>=1000000]
a$VAL[a$VAL>=1000000]
a$VAL
a$VAL>=1000000
a$VAL[a$VAL>=1000000]
a$VAL[a$VAL=24]
a$VAL[a$VAL==24]
length(a$VAL[a$VAL==24])
length(a$VAL[a$VAL>=24])
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx ",destfile='data.xlsx', method='curl')
c  <- c(7:15)
r  <- c(18:23)
c
r
dat  <- read.xlsx('data.xlsx', sheetIndex=1, colIndex=c, rowIndex=r)
library(xlsx)
install.packages("xlsx", lib="/Users/damiensonnerat/Downloads/xlsx/")
library(xlsx)
library(xlsx, lib.loc='/var/folders/pf/1mvxx1013rx7j_8hzksp6x8w0000gn/T//RtmpzZ4TC0/downloaded_packages')
dat  <- read.xlsx('data.xlsx', sheetIndex=1, colIndex=c, rowIndex=r)
library(xlsx, lib.loc='xlsx')
?install.package
?install.packages
search
search()
library(xlsx, lib.loc='/var/folders/pf/1mvxx1013rx7j_8hzksp6x8w0000gn/T//RtmpzZ4TC0/downloaded_packages/xlsx')
library(xlsx, lib.loc='/var/folders/pf/1mvxx1013rx7j_8hzksp6x8w0000gn/T//RtmpzZ4TC0/downloaded_packages/xlsx/')
install.packages("xlsx", lib="/Users/damiensonnerat/Downloads/xlsx/", destdir="/Users/damiensonnerat/Documents/Cours data scientist/Johns Hopkins University")
library(xlsx, lib.loc='/Users/damiensonnerat/Documents/Cours data scientist/Johns Hopkins University')
install.packages("xlsx")
library(xlsx)
dat  <- read.xlsx('data.xlsx', sheetIndex=1, colIndex=c, rowIndex=r)
sum(dat$Zip*dat$Ext,na.rm=T)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml",destfile='data.xml', method='curl')
library(XML)
install.packages("XML")
library(XML)
data  <- xmlTreeParse('data.xml', suseInternal=TRUE)
data  <- xmlTreeParse('data.xml', useInternal=TRUE)
data
root  <- xmlRoot(data)
root
xpath(root, "//row/zipcode", xmlValue)
xpathSApply(root, "//row/zipcode", xmlValue)
zip  <- xpathSApply(root, "//row/zipcode", xmlValue)
zip
a  <- subset(zip,zip==21231)
a
length(a)
DT  <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
install.packages("data.table")
DT  <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
?fread
install.packages("fread")
library("fread")
library("data.table")
DT  <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",destfile='data2.csv', method='curl')
DT  <- fread("data2.csv")
DT
DT$pwgtp15
mean(DT$pwgtp15,by=DT$SEX)
DT[,mean(pwgtp15),by=SEX]
sample(1:5)
?sample
sample(1:5, replace=true)
sample(1:5, replace=T)
?which
d  <-  c(1,3,5,NA,6)
d
d[d>2]
d>2
which(d>2)
d
order(d)
d <- sample(1:5)
d
order(d)
?table
install.packages(c("boot", "class", "cluster", "codetools", "foreign", "lattice", "manipulate", "MASS", "Matrix", "mgcv", "nlme", "nnet", "Rcpp", "RCurl", "rpart", "spatial", "stringr", "survival"))
library(Hmisc)
version
packageStatus()
install.packages(c("boot", "codetools", "lattice", "manipulate", "MASS", "Matrix", "mgcv"))
packageStatus()
library(dplyr)
library(plyr)
install.packages("dplyr")
source(dplyr)
library("dplyr")
library("plyr")
?makes.names
?make.names
?sub
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="c:/DataScienceFiles/DataScience_Project/samsungdata.zip")
gl(2,3)
gl(2,3,labels=c('a','b'))
gl(2,10,labels=c('a','b'))
seq(0,1,length=4)
install.packages('lattice')
install.packages('nlme')
?print.trellis
hist(rnorm(12,sd=0.2))
hist(rnorm(12,mean=5,sd=0.2))
hist(rnorm(100,mean=5,sd=0.2))
hist(rnorm(100,mean=c(5,50),sd=0.2))
?dist
dist(c(15,10))
T?
45ref
?t
?image
a  <- matrix(2,3,c(1,2,1,2,1,2))
image(a)
a
?matrix
a  <- matrix(c(1,2,1,2,1,2),2,3)
image(a)
a
?image
?PLOT
?plot
?scale
sample(1:10, size=40)
sample(1:100, size=40, replace = FALSE)
a  <- matrix(1:400,dim=c(40,10))
a  <- matrix(1:400,40,10)
a
a[1]
a[10]
a[400]
a[1,2]
a[1][2]
a[1,2]
a[12]
a
?diag
diag(c(1,2))
?image
?unclass
?which.max
?table
?tapply
?barplot
?cumchange
?cumChange
?cumsum
?closeAllConnections
?grepl
letters
o.1 + 0.2 * 2 + 0.3 * 3 + 0.4 * 4
0.1 + 0.2 * 2 + 0.3 * 3 + 0.4 * 4
(0.75*0.30)
(0.75*0.30)/(0.75*0.30+(1-0.52)*(1-0.30))
(0.75*0.30)/(0.75*0.30+(1-0.52)*(1-0.30))
?along
seq_along(data)
seq_along(data[1])
seq_along(data[[1]])
?seq_along
seq_len(2)
seq_len(3)
seq_len(nrwo(data))
seq_len(nrow(data))
nrow(data())
nrow(data
)
source(lireGed.R)
source('lireGed.R')
dir()
a = (70-80)/10
a
?pnorm
pnorm(-1)
pnorm(70, mean=80, sd=10)
qnorm(95,mean=1100,sd=75)
qnorm(0.95,mean=1100,sd=75)
qnorm(0.95,mean=1100,sd=75/sqr(100))
str(4)
sqrt(4)
qnorm(0.95,mean=1100,sd=75/sqrt(100))
?rbinom
pbinom(q=5, size=5,prog=0.5)
pbinom(q=5, size=5,prob=0.5)
pbinom(q=4, size=5,prob=0.5)
pbinom(q=4, size=5,prob=0.5, lower.tail = FALSE)
?pnorm
pnorm(q=14,mean=15,sd=1)
pnorm(q=14,mean=15,sd=1)
10/sqrt(100)
pnorm(q=15,mean=15,sd=1)-pnorm(q=14,mean=14,sd=1)
pnorm(q=15,mean=15,sd=1)-pnorm(q=14,mean=15,sd=1)
-pnorm(q=15,mean=15,sd=1,lower.tail = F)+pnorm(q=14,mean=15,sd=1,lower.tail = F)
?runif
?runif(1000)
runif(1000)
mean(runif(1000))
?ppois
ppois(q=10,lambda = 3*15)
ppois(10,lambda = 3*15)
ppois(10,lambda = 3*5)
?pbinom
pbinom(q=4,size=5,prob=0.5,lower.tail = F)
pbinom(q=3,size=5,prob=0.5,lower.tail = F)
pbinom(3,size=5,prob=0.5,lower.tail = F)
?pnorm
pnorm(q=14,mean = 15, sd=1)
pnorm(q=16,mean=15,sd=1)-pnorm(q=14,mean=15,sd=1)
mean(c(T,F,T))
mean(c(T,T,T))
?relevel
?I
?relevel
4^.5
100^.5
sqrt(100)
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any em
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
rep(1,2)
rep(1:40,2)
rep(1:2,40)
?rep
rep(1:1000,40)
lambda <-  0.2 #exponential distribution parameter
n <- 40 #sample size
nbsimulation <- 1000 #Number of simulations
data <- data.frame(numsimu=rep(1:nbsimulation,n), value=rexp(n*nbsimulation, lambda))
lambda <-  0.2 #exponential distribution parameter
n <- 40 #sample size
nbsimulation <- 1000 #Number of simulations
data <- data.frame(numsimu=rep(1:nbsimulation,n), value=rexp(n*nbsimulation, lambda))
View(data)
View(data)
data <- data.frame(numsimu=rep(1:nbsimulation,n), value=rexp(n*nbsimulation, lambda))
?agregate
?aggregate
aggregate(data=data, by=list('numsimu'), FUN=mean)
aggregate(data, by=list('numsimu'), FUN=mean)
aggregate(data$, by=list('numsimu'), FUN=mean)
simulataeddata <- data.frame(numsimu=rep(1:nbsimulation,n), value=rexp(n*nbsimulation, lambda))
aggregate(simulataeddata$value, by=list(simulataeddata$value), FUN=mean)
aggregate(simulataeddata$value, by=list(simulataeddata$numsimu), FUN=mean)
aggregate(simulataeddata$value, by=list(simulataeddata$numsimu), FUN=mean)
names(samplemean) <- c('numsimu','mean')
samplemean <- aggregate(simulataeddata$value, by=list(simulataeddata$numsimu), FUN=mean)
names(samplemean) <- c('numsimu','mean')
head(samplemean)
View(data)
View(data)
mean <- mean(samplemean$mean)
hist(samplemean$mean)
?hist
hist(samplemean$mean, main='Sample Mean versus Theoretical Mean', xlab='Means of samples of size 40')
?line
abline(5)
?abline
abline(5)
abline(v = mean(samplemean$mean), col = "red")
abline(v = 1/lambda, col = "blue")
legend("topright", legend = c("Simulated mean"), col = c("red"))
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 15)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 1)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 2)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 3)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 4)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 5)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 6)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 7)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 8)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 5)
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 7)
?legend
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 7 , border='white')
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 1 , border='white')
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 2 , border='white')
legend("topright", legend = c("Simulated mean"), col = c("red"), pch = 3 , border='white')
legend("topright", legend = c("Simulated mean"), col = c("red"), lty=c(1,1) , border='white')
legend("topright", legend = c("Simulated mean","Theoretical mean"), col = c("red","blue"), lty=c(1,1) , border='white')
legend("topright", legend = c("Simulated mean","Theoretical mean"), col = c("red","blue"), lty=c(1,1) , border='white')
?var
samplemean <- aggregate(simulateddata$value, by=list(simulateddata$simunum), FUN=var)
names(samplemean) <- c('simunum','var')
head(samplemean)
length(samplemean)
sqrt(0,61)
sqrt(0.61)
hist(simulateddata$value[1:nbsimulation])
simulateddata <- data.frame(simunum=rep(1:nbsimulation,n), value=rexp(n*nbsimulation, lambda))
hist(simulateddata$value[1:nbsimulation])
hist(samplemean$mean, main='Sample Mean', xlab='Means of samples of size 40', freq = FALSE)
hist(samplemean$mean, main='Sample Mean', xlab='Means of samples of size 40', freq = FALSE)
?hist
data(ToothGrowth)
data(ToothGrowth)
ls
ls()
str(ToothGrowth)
head(ToothGrowth)
unique(ToothGrowth$dose)
hist(ToothGrowth$len)
?count
aggregate(ToothGrowth$len, by=list(ToothGrowth$supp, ToothGrowth$dose), FUN=nrow)
aggregate(ToothGrowth$len, by=list(ToothGrowth$supp, ToothGrowth$dose), FUN=count.fields
)
aggregate(ToothGrowth$len, by=list(ToothGrowth$supp, ToothGrowth$dose), FUN=length)
?boxplot
boxplot(len ~ supp + dose, data=ToothGrowth)
install.packages("http://mirror.ibcp.fr/pub/CTAN/systems/mac/mactex/mactex-20150613.pkg")
?hist
hist(ToothGrowth$len)
hist(ToothGrowth$len, width=30)
boxplot(len ~ supp + dos, data=ToothGrowth)
boxplot(len ~ supp + dose, data=ToothGrowth)
?legend
t.test(len ~ supp, paired=FALSE, var.equal=TRUE, data=ToothGrowth)
t.test(len ~ supp, paired=FALSE, var.equal=TRUE, data=ToothGrowth)
only1dose <- subset(ToothGrowth, dose = 1)
only1dose <- subset(ToothGrowth, dose = 13)
View(only1dose)
View(only1dose)
only1dose <- subset(ToothGrowth, dose = 1.0)
only1dose <- subset(ToothGrowth, ToothGrowth$dose = 1.0)
only1dose <- subset(ToothGrowth, ToothGrowth$dose = 1.0)
?subset
only1dose <- ToothGrowth[dose = 1.0]
only1dose <- ToothGrowth[dose == 1.0]
only1dose <- ToothGrowth[ToothGrowth$dose = 1.0]
only1dose <- ToothGrowth[ToothGrowth$dose == 1.0]
ToothGrowth$dose = 0.5
data(ToothGrowth)
ToothGrowth$dose == 0.5
ToothGrowth$dose == 1
only1dose <- ToothGrowth[ToothGrowth$dose == 1,]
?t.test
?readLines
?dendrogram
?dendrapply
?dendrogram
data(bird.orders)
x <- rep(0, 4)
names(x) <- c("A", "B", "C", "D")
anc <- evolve.phylo(bird.orders, x, 1)
plot(anc, edge.width = 3, plot.node.values = TRUE)
par(mfrow = c(2, 2), mar = c(5.5, 0, 0, 0))
plot(anc, edge.width = 3, type = "r")
data(bird.orders)
n <- 100
x2 <- 1:n
x1 <- .01 * x2
y <- -x1 + x2
plos(x1,y)
plot(x=x1,y=y)
plot(x=x2,y=y)
plot(x=x1,y=y)
plot(x=x2,y=y)
plot(x=x1,y=y)
hatvalues(mtcars)
?mtcars
pairs(mtcars, main = "mtcars data")
coplot(mpg ~ disp | as.factor(cyl), data = mtcars,
panel = panel.smooth, rows = 1)
?hatvalues
sd(mtcars)
data(mtcars)
data(mtcars)
q =mtacars
q =mtcars
View(mtcars)
View(mtcars)
sd(d)
sd(q)
str(q)
cor(data.matrix(mtcars))
cor(data.matrix(mtcars))
cor(data.matrix(mtcars))
View(mtcars)
View(mtcars)
variables <- mtcars[, 2:11]
View(variables)
View(variables)
summary(lm(mpg ~ ., data=mtcars))
?mtcars
?round
cor(round(data.matrix(variables),1))
round(1.123,1)
round(cor(data.matrix(variables)),1)
round(cor(data.matrix(variables)),1) >= 0.7
round(cor(data.matrix(variables)),1) >= 0.8
round(cor(data.matrix(variables)),1) >= 0.7
head(mtcars)
head(mtcars[,mpg])
head(mtcars[,mpg])
?with
head(cbind(mtcars$cyl,mtcars$disp))
head(with(mtcars, cbind(cyl,disp)))
?mtcars
mtcars[mtcars$am == 0]$gear
mtcars[mtcars$am == 0,]$gear
summary(lm(mpg ~ ., data = mtcars))
summary(lm(mpg ~ am, cyl, carb, data = mtcars))
summary(lm(mpg ~ am + cyl + carb, data = mtcars))
summary(lm(mpg ~ ., data = mtcars))
summary(lm(mpg ~ ., data = mtcars))$coef
cbind(coef, coef[4])
cbind(coef, coef[,4])
str(coef)
allVaraiblesLmcoef <- summary(lm(mpg ~ ., data = mtcars))$coef
str(allVaraiblesLmcoef)
cbind(allVaraiblesLmcoef, allVaraiblesLmcoef[4])
allVaraiblesLmcoef
allVaraiblesLmcoef[,4]
cbind(allVaraiblesLmcoef, allVaraiblesLmcoef[,4])
cbind(allVaraiblesLmcoef, allVaraiblesLmcoef[,4] <= .05)
summary(lm(mpg ~ drat * am * gear * vs * cyl * disp * hp * wt * carb * qsec, data = mtcars))$coef
summary(lm(mpg ~ am + cyl + carb, data = mtcars))
summary(lm(mpg ~ I(factor(am) + cyl + carb, data = mtcars))$coef
summary(lm(mpg ~ I(factor(am)) + cyl + carb, data = mtcars))$coef
View(mtcars)
View(mtcars)
summary(lm(mpg ~ I(factor(am)) + cyl + carb, data = mtcars))$coef
?plot
?plot.lm
?mtcars
max(mtcars$mpg)
pr = predict(fit, df = fit$df)
fit <- lm(mpg ~ am + cyl + carb, data = mtcars)
pr = predict(fit, df = fit$df)
pr
unique(mtcars$am)
1.3094130 *  3.240367
?mtcars
round(0.65,1)
round(0.66,1)
9.480766e-03
dpois(0:20, lambda = 3)
dpois(20, lambda = 3)
dpois(20, lambda = 3)
dpois(20, lambda = 3)
?dpois
?norm
?rnorm
remove.packages(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
remove.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
remove.packages('caret')
remove.packages('ElemStatLearn')
remove.packages('pgmm')
remove.packages('rpart')
?install.packages
version
packageurl <- "https://cran.r-project.org/src/contrib/AppliedPredictiveModeling_1.1-6.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
remove.packages('AppliedPredictiveModeling')
packageurl <- "https://cran.r-project.org/src/contrib/Archive/rpart/rpart_4.1-8.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
packageurl <- "https://cran.r-project.org/src/contrib/Archive/rpart/rpart_4.1-8.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
setwd("~/Documents/Cours data scientist/Johns Hopkins University/Data product/shinyProject/documentation")
